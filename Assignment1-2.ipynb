{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Text Preprocessing with NLTK and spaCy","metadata":{}},{"cell_type":"code","source":"import nltk\nimport spacy\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n# download NLTK\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('wordnet2022')\nnltk.download('stopwords')\n\n# Initializing spaCy\nnlp = spacy.load(\"en_core_web_sm\")\n\n# temp fix for lookup error.\n! cp -rf /usr/share/nltk_data/corpora/wordnet2022 /usr/share/nltk_data/corpora/wordnet","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-18T16:32:40.471790Z","iopub.execute_input":"2025-02-18T16:32:40.472698Z","iopub.status.idle":"2025-02-18T16:32:41.908198Z","shell.execute_reply.started":"2025-02-18T16:32:40.472663Z","shell.execute_reply":"2025-02-18T16:32:41.906749Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\n[nltk_data] Downloading package wordnet2022 to /usr/share/nltk_data...\n[nltk_data]   Package wordnet2022 is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"sample_text = \"In the heart of the ancient forest, where the moonlight wove silver threads through the emerald canopy, Elara whispered an incantation long forgotten by time. The air shimmered as glowing runes spiraled around her, their golden light pulsing with an unseen rhythm. A gust of wind carried the scent of lavender and old parchment, and in the silence that followed, the ancient oak before her groaned, its bark twisting to reveal a hidden doorway. Beyond it lay a realm untouched by mortal hands, where stars floated like fireflies and rivers sang in voices older than the world itself.\"\n\n# NLTK tokenization\nnltk_tokens = word_tokenize(sample_text)\nprint(\"NLTK Tokens:\", nltk_tokens)\n\n# spaCy tokenization\ndoc = nlp(sample_text)\nspacy_tokens = [token.text for token in doc]\nprint(\"spaCy Tokens:\", spacy_tokens)\n\n# NLTK lemmatization and stopword removal\nlemmatizer = WordNetLemmatizer()\nnltk_stopwords = set(stopwords.words('english'))\nnltk_processed = [lemmatizer.lemmatize(word.lower()) for word in nltk_tokens if word.lower() not in nltk_stopwords]\nprint(\"NLTK Processed:\", nltk_processed)\n\n# spaCy lemmatization and stopword removal\nspacy_processed = [token.lemma_.lower() for token in doc if not token.is_stop]\nprint(\"spaCy Processed:\", spacy_processed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T16:32:41.910023Z","iopub.execute_input":"2025-02-18T16:32:41.910362Z","iopub.status.idle":"2025-02-18T16:32:41.970991Z","shell.execute_reply.started":"2025-02-18T16:32:41.910330Z","shell.execute_reply":"2025-02-18T16:32:41.969708Z"}},"outputs":[{"name":"stdout","text":"NLTK Tokens: ['In', 'the', 'heart', 'of', 'the', 'ancient', 'forest', ',', 'where', 'the', 'moonlight', 'wove', 'silver', 'threads', 'through', 'the', 'emerald', 'canopy', ',', 'Elara', 'whispered', 'an', 'incantation', 'long', 'forgotten', 'by', 'time', '.', 'The', 'air', 'shimmered', 'as', 'glowing', 'runes', 'spiraled', 'around', 'her', ',', 'their', 'golden', 'light', 'pulsing', 'with', 'an', 'unseen', 'rhythm', '.', 'A', 'gust', 'of', 'wind', 'carried', 'the', 'scent', 'of', 'lavender', 'and', 'old', 'parchment', ',', 'and', 'in', 'the', 'silence', 'that', 'followed', ',', 'the', 'ancient', 'oak', 'before', 'her', 'groaned', ',', 'its', 'bark', 'twisting', 'to', 'reveal', 'a', 'hidden', 'doorway', '.', 'Beyond', 'it', 'lay', 'a', 'realm', 'untouched', 'by', 'mortal', 'hands', ',', 'where', 'stars', 'floated', 'like', 'fireflies', 'and', 'rivers', 'sang', 'in', 'voices', 'older', 'than', 'the', 'world', 'itself', '.']\nspaCy Tokens: ['In', 'the', 'heart', 'of', 'the', 'ancient', 'forest', ',', 'where', 'the', 'moonlight', 'wove', 'silver', 'threads', 'through', 'the', 'emerald', 'canopy', ',', 'Elara', 'whispered', 'an', 'incantation', 'long', 'forgotten', 'by', 'time', '.', 'The', 'air', 'shimmered', 'as', 'glowing', 'runes', 'spiraled', 'around', 'her', ',', 'their', 'golden', 'light', 'pulsing', 'with', 'an', 'unseen', 'rhythm', '.', 'A', 'gust', 'of', 'wind', 'carried', 'the', 'scent', 'of', 'lavender', 'and', 'old', 'parchment', ',', 'and', 'in', 'the', 'silence', 'that', 'followed', ',', 'the', 'ancient', 'oak', 'before', 'her', 'groaned', ',', 'its', 'bark', 'twisting', 'to', 'reveal', 'a', 'hidden', 'doorway', '.', 'Beyond', 'it', 'lay', 'a', 'realm', 'untouched', 'by', 'mortal', 'hands', ',', 'where', 'stars', 'floated', 'like', 'fireflies', 'and', 'rivers', 'sang', 'in', 'voices', 'older', 'than', 'the', 'world', 'itself', '.']\nNLTK Processed: ['heart', 'ancient', 'forest', ',', 'moonlight', 'wove', 'silver', 'thread', 'emerald', 'canopy', ',', 'elara', 'whispered', 'incantation', 'long', 'forgotten', 'time', '.', 'air', 'shimmered', 'glowing', 'rune', 'spiraled', 'around', ',', 'golden', 'light', 'pulsing', 'unseen', 'rhythm', '.', 'gust', 'wind', 'carried', 'scent', 'lavender', 'old', 'parchment', ',', 'silence', 'followed', ',', 'ancient', 'oak', 'groaned', ',', 'bark', 'twisting', 'reveal', 'hidden', 'doorway', '.', 'beyond', 'lay', 'realm', 'untouched', 'mortal', 'hand', ',', 'star', 'floated', 'like', 'firefly', 'river', 'sang', 'voice', 'older', 'world', '.']\nspaCy Processed: ['heart', 'ancient', 'forest', ',', 'moonlight', 'wove', 'silver', 'thread', 'emerald', 'canopy', ',', 'elara', 'whisper', 'incantation', 'long', 'forget', 'time', '.', 'air', 'shimmer', 'glow', 'rune', 'spiral', ',', 'golden', 'light', 'pulse', 'unseen', 'rhythm', '.', 'gust', 'wind', 'carry', 'scent', 'lavender', 'old', 'parchment', ',', 'silence', 'follow', ',', 'ancient', 'oak', 'groaned', ',', 'bark', 'twisting', 'reveal', 'hidden', 'doorway', '.', 'lie', 'realm', 'untouched', 'mortal', 'hand', ',', 'star', 'float', 'like', 'firefly', 'river', 'sing', 'voice', 'old', 'world', '.']\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"NLTK оставляет некоторые слова неизменёнными (например, \"whispered\", \"shimmered\", \"twisting\").\nspaCy меняет слова более кардинально (\"forgotten\" → \"forget\", \"glowing\" → \"glow\", \"spiraled\" → \"spiral\"), тогда как NLTK этого не делает.","metadata":{}},{"cell_type":"markdown","source":"# 2. Named Entity Recognition (NER) with spaCy","metadata":{}},{"cell_type":"code","source":"import spacy\nfrom spacy import displacy\n\nnlp = spacy.load(\"en_core_web_sm\")\n\ntext = \"Elon Musk, the CEO of Tesla and SpaceX, announced that the new Tesla Model S will be released in September 2025. The event took place in San Francisco, where hundreds of journalists attended. Microsoft and Google are also investing heavily in AI research, with a projected budget of $50 billion by 2030.\"\n\n# Application of spaCy for NER\ndoc = nlp(text)\n\n# Output of found named entities\nprint(\"Named Entities:\")\nfor ent in doc.ents:\n    print(f\"{ent.text} ({ent.label_})\")\n\n# Visualization of named entities\ndisplacy.render(doc, style=\"ent\", jupyter=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T16:32:41.972696Z","iopub.execute_input":"2025-02-18T16:32:41.973035Z","iopub.status.idle":"2025-02-18T16:32:42.904920Z","shell.execute_reply.started":"2025-02-18T16:32:41.973008Z","shell.execute_reply":"2025-02-18T16:32:42.903992Z"}},"outputs":[{"name":"stdout","text":"Named Entities:\nElon Musk (PERSON)\nTesla (ORG)\nTesla Model S (PERSON)\nSeptember 2025 (DATE)\nSan Francisco (GPE)\nhundreds (CARDINAL)\nMicrosoft (ORG)\nGoogle (ORG)\nAI (GPE)\n$50 billion (MONEY)\n2030 (DATE)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Elon Musk\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n, the CEO of \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tesla\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n and SpaceX, announced that the new \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tesla Model S\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n will be released in \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    September 2025\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n</mark>\n. The event took place in \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    San Francisco\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n, where \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    hundreds\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n</mark>\n of journalists attended. \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Microsoft\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n and \n<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Google\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n</mark>\n are also investing heavily in \n<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    AI\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n</mark>\n research, with a projected budget of \n<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    $50 billion\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n</mark>\n by \n<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    2030\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n</mark>\n.</div></span>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# 3. Text Vectorization using Transformers","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\nimport torch\n\n# Loading the pre-trained model and tokenizer\nmodel_name = \"bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = BertModel.from_pretrained(model_name)\n\ntext = \"Machine learning is transforming the world of artificial intelligence.\"\n\n# Tokenization\ninputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n\n# Obtaining the model's hidden states\nwith torch.no_grad():\n    outputs = model(**inputs)\n    hidden_states = outputs.last_hidden_state\n\n# Extracting embeddings\nword_embeddings = hidden_states.squeeze(0)\nprint(\"Word embeddings shape:\", word_embeddings.shape)\n\nprint(\"First 5 word embeddings:\")\nprint(word_embeddings[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T16:32:42.906234Z","iopub.execute_input":"2025-02-18T16:32:42.906514Z","iopub.status.idle":"2025-02-18T16:32:43.369713Z","shell.execute_reply.started":"2025-02-18T16:32:42.906491Z","shell.execute_reply":"2025-02-18T16:32:43.368811Z"}},"outputs":[{"name":"stdout","text":"Word embeddings shape: torch.Size([12, 768])\nFirst 5 word embeddings:\ntensor([[-0.2406, -0.0205, -0.1639,  ..., -0.5280,  0.0740,  0.4706],\n        [ 0.2976,  0.2279, -0.1190,  ..., -0.0478,  0.5451,  0.3846],\n        [-0.1905,  0.2525, -0.1623,  ..., -1.0566,  0.3143,  0.4100],\n        [-0.1254,  0.2789, -0.3254,  ...,  0.0573, -0.1851,  0.3142],\n        [-0.1019, -0.4838,  0.0465,  ..., -0.5256, -0.1013, -0.0301]])\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# 4. Sentiment Analysis with Transformers","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\n\n# Loading the pre-trained sentiment analysis pipeline\nsentiment_analyzer = pipeline(\"sentiment-analysis\")\n\nsentences = [\n    \"I absolutely love this product! It's amazing.\",\n    \"The service was terrible, I will never come back.\",\n    \"It's an okay experience, nothing special but not bad either.\",\n    \"This is the worst movie I have ever seen.\",\n    \"The food was delicious and the staff was very friendly.\"\n]\n\n# Performing sentiment analysis on the sentences\nresults = sentiment_analyzer(sentences)\n\nfor sentence, result in zip(sentences, results):\n    print(f\"Sentence: {sentence}\")\n    print(f\"Sentiment: {result['label']}, Confidence: {result['score']:.4f}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T16:32:43.370742Z","iopub.execute_input":"2025-02-18T16:32:43.371134Z","iopub.status.idle":"2025-02-18T16:32:43.712117Z","shell.execute_reply.started":"2025-02-18T16:32:43.371099Z","shell.execute_reply":"2025-02-18T16:32:43.711050Z"}},"outputs":[{"name":"stderr","text":"No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nDevice set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"Sentence: I absolutely love this product! It's amazing.\nSentiment: POSITIVE, Confidence: 0.9999\n\nSentence: The service was terrible, I will never come back.\nSentiment: NEGATIVE, Confidence: 0.9990\n\nSentence: It's an okay experience, nothing special but not bad either.\nSentiment: POSITIVE, Confidence: 0.9951\n\nSentence: This is the worst movie I have ever seen.\nSentiment: NEGATIVE, Confidence: 0.9998\n\nSentence: The food was delicious and the staff was very friendly.\nSentiment: POSITIVE, Confidence: 0.9999\n\n","output_type":"stream"}],"execution_count":17}]}